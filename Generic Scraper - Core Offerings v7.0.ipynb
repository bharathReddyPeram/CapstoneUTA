{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Web Scraper - Core Offerings (Products & Solutions)\n",
    "\n",
    "__Summary__: This is a generic web scraper to extract details related to Products, Solutions, Services, Platforms & Clients of companies\n",
    "\n",
    "__The scraper works as follows__:\n",
    "- Input file containing the URLs of companies is read\n",
    "- Selenium opens the URL in browser and extract the page source using \n",
    "- The source html data is parsed using BeautifulSoup\n",
    "- Required data is then extracted, filtered and processed\n",
    "  - Identify Stop words and Stop phrases\n",
    "- Final output is saved in an output file \n",
    "   - Errors are also saved in an error file\n",
    "\n",
    "__Next steps__: \n",
    "- The current scraper uses hardcoded rules to try and extract products, solution and services. Your task is to modify the scraper so that it uses AI to pull the products, solutions and services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-b8001e57c9e6>:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "%run Linkedinscraping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Function to download the browser and parse the html page source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_browser(my_url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    # Selenium accesses the Chrome browser driver in incognito mode and without actually opening a browser window \n",
    "    # (headless argument). Any certificates errors are ignored\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--incognito')\n",
    "    options.add_argument('--headless')\n",
    "\n",
    "    browser = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "    #     browser = webdriver.Firefox(executable_path = executable_path, options = options)\n",
    "    #     browser.get(\"https://{}\".format(my_url))\n",
    "\n",
    "    browser.get(my_url)\n",
    "    # Pass the page source to Beautiful Soup for parsing\n",
    "    page_soup = BeautifulSoup(browser.page_source, 'lxml')\n",
    "    #page_soup2 = soup(browser.page_source, 'lmxl')\n",
    "    return (browser, page_soup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarization model inputs\n",
    "\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Capstone/autotrain-summarization-capstone-mode-2151969392\"\n",
    "headers_summarization = {\"Authorization\": f\"Bearer {'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'}\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers_summarization, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function to initialize the lists. Will be called for every URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lists():\n",
    "    products = []\n",
    "    solutions = []\n",
    "    services = []\n",
    "    platforms = []\n",
    "    clients = []\n",
    "    page_text = []\n",
    "    overviewpage_link = []\n",
    "    linkedinpage_link = []\n",
    "    overview_text = []\n",
    "    \n",
    "    return (products, solutions, services, platforms, clients, page_text, overviewpage_link, linkedinpage_link, overview_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify Input / Output files\n",
    "- Read the Input file and create a list of Company name and URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = r'companies data.xlsx'\n",
    "out_file = r'webscraping output.csv'\n",
    "out_file_err = r'error file.csv'\n",
    "\n",
    "header = ['Company Name', 'Link', 'Products', 'Solutions', 'Services', 'Platforms', 'Clients', 'Page_Text', 'overviewpage_Link', 'linkedinpage_Link','overview_Text','Overview_linkedIn','Industry_linlkedIn','Specialities_linkedIn','Company_Overview_Summary']\n",
    "header_err = ['Company Name', 'Link', 'Error']\n",
    "\n",
    "fh_in = open(in_file, 'r')\n",
    "df = pd.read_excel(in_file)\n",
    "fh_in.close()\n",
    "\n",
    "input_list = df[['Company Name', 'Link']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simplify Healthcare, Inc.</td>\n",
       "      <td>https://simplifyhealthcare.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medecision</td>\n",
       "      <td>https://www.medecision.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ingenious Med Inc.</td>\n",
       "      <td>https://ingeniousmed.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name                            Link\n",
       "0  Simplify Healthcare, Inc.  https://simplifyhealthcare.com\n",
       "1                 Medecision     https://www.medecision.com/\n",
       "2         Ingenious Med Inc.       https://ingeniousmed.com/"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Write data to be written into output file for every URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file():    \n",
    "    temp = []\n",
    "    temp = [comp_name, link, ' | '.join(products_clean), ' | '.join(solutions_clean), ' | '.join(services_clean), ' | '.join(platforms_clean), ' | '.join(clients_clean), ' | '.join(page_text_clean), ' | '.join(overviewpage_link_clean), ' | '.join(linkedinpage_link_clean),  ' | '.join(overview_text_clean),  ' | '.join(overviewlk1),  ' | '.join(industrylk1),  ' | '.join(specialitieslk1),  ' | '.join(Company_overview_summary)] \n",
    "    out.append(temp)\n",
    "    return ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Write errors encountered during runtime for any input URL into error file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_error_file():\n",
    "    temp_err = []\n",
    "    temp_err = [comp_name, link, e] \n",
    "    out_err.append(temp_err)\n",
    "    return ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Define the Keywords for output file columns, Stop Words and Stop Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_key = ['product', 'software', 'consult']\n",
    "\n",
    "solutions_key = ['solution', 'care', 'value', 'industry', 'offer', 'practice', 'capabili', 'practice', 'virtual', \n",
    "                 'monitor', 'real' 'clinical', 'surveillance', 'what', 'how', 'help', 'systems']\n",
    "\n",
    "services_key = ['service']\n",
    "\n",
    "platforms_key = ['platform', 'oprx']\n",
    "\n",
    "clients_key = ['client', 'partner', 'serve']\n",
    "\n",
    "overviewlinks_key = ['about', 'company']\n",
    "\n",
    "linkedin_key = 'linkedin.com/company'\n",
    "\n",
    "# Add stop words in lower case\n",
    "stop_words = ['read report', 'careers', 'industry report', 'read the case study', 'read the report', 'join our team', \n",
    "              'overview', 'partners', 'customers', 'success stories', 'blogs', 'menu', 'previous', 'next', \n",
    "              'events & webinars', 'education & training', 'white paper', 'research paper', 'resources', 'terms of use', \n",
    "              'news', 'podcasts', 'request a demo', 'get a demo', 'our manifesto', 'schedule a demo', 'request demo',\n",
    "              'cookie policy', 'blog', 'events', 'webinars', 'downloads', 'about us', 'about', 'advisors', 'contact', \n",
    "              'privacy', 'schedule a free demo', 'login', 'read now', 'press releases', 'flip through our magazine', \n",
    "              'brochures', 'case studies', 'case study', 'ebooks', 'infographics', 'magazines', 'videos', 'white papers', \n",
    "              'discover all our resources', 'learn more about who we are', 'executive team', 'board of directors', \n",
    "              'regulatory and compliance', 'see more demos', 'watch the video', 'listen to the podcast', 'news & events', \n",
    "              'brand', 'developer network', 'view webinar', 'read story', 'view event', 'log in', 'log out',\n",
    "              'start the conversation now', 'code of ethics', 'privacy policy', 'terms and conditions', 'skip to content', \n",
    "              'home', 'request your demo today', 'read more', 'faq & help center', 'sign in', 'sign out', 'learn more', \n",
    "              'get in touch', 'view testimonials', 'terms of service', 'contact us', 'new registration click here', \n",
    "              'sites', 'sumo', 'faqs', 'faq', 'terms & conditions', 'site map', 'sitemap', 'customer stories', \n",
    "              'support', 'back to top', 'help', 'connect', 'news & blog', 'log in / sign up', 'scroll to top', 'follow', \n",
    "              'legal & privacy', 'close menu', 'terms of use and privacy policy', 'email', 'call', 'terms', 'company', \n",
    "              'jobs', 'manifesto', 'awards', 'news / events', 'join us', 'meet the team', 'rss', 'get started', 'tour', \n",
    "              'read article', 'read more reviews', 'accessibility', 'i understand', 'poland', 'switzerland', \n",
    "              'asia pacific', 'czechia', 'denmark', 'germany', 'norway', 'middle east & africa', 'ireland', 'italy', \n",
    "              'netherlands', 'france', 'brazil', 'united states', 'austria', 'turkey', 'sweden', 'canada', 'india', \n",
    "              'belgium', 'south africa', 'benelux', 'russia', 'united kingdom', 'romania', 'spain', 'slovakia', \n",
    "              'australia', 'argentina', 'chile', 'colombia', 'ecuador', 'mexico', 'peru', 'panama', 'portugal', \n",
    "              'new zealand', 'online courses', 'to the top', 'to top', 'book an appointment', 'our story', 'view demo', \n",
    "              'tutorials', 'demo', 'watch now', 'shop online', 'live demo', 'view demo', 'schedule demo', 'open positions',\n",
    "              'livechat', 'brochure', 'book a demo', 'call us', 'find us', 'deutsch', 'french', 'japanese', 'portuguese', \n",
    "              'english', 'chinese', 'nederlands', 'request a quote', 'accept', 'decline','requestdemotoday', 'history',\n",
    "              'read the study', 'read the post', 'my account', 'customer portal', 'share your experience', 'back', \n",
    "              'shop', 'back to dashboard', 'demos', 'log-in', 'uk & europe', 'asia-pacific', 'register', 'reach us', \n",
    "              'term of use', 'help center', 'chat', 'more', 'costa rica', 'croatia', 'czech republic', 'egypt', 'finland', \n",
    "              'hong kong', 'hungary', 'indonesia', 'israel', 'japan', 'korea', 'lithuania', 'luxembourg', 'malaysia',\n",
    "              'morocco', 'nigeria', 'norway', 'philippines', 'qatar', 'saudi arabia', 'singapore', 'thailand', 'taiwan',\n",
    "              'tunisia', 'united arab emirates', 'vietnam', 'singapore', 'skype', 'whatsapp', 'glossary', 'search'] \n",
    "\n",
    "stop_strings = ['download', 'webinar', 'case stud', 'explore', 'whitepaper', 'reviews', 'disclosure', 'register now',\n",
    "                'press', 'click', 'login', 'blog', 'about', 'scroll', 'council', 'news', 'sign up', 'contact us', 'china',  \n",
    "                'questions', 'feedback', 'free', 'read story', 'conversation', 'our story', 'terms of use', 'privacy', \n",
    "                'cookie', 'view all', 'navigation', 'legal', \"let's talk\", \"let's connect\", 'watch video', 'awards', 'faq',\n",
    "                'leadership','get started', 'more info', 'more details', 'contact support', 'twitter', 'facebook', \n",
    "                'youtube', 'linkedin', 'wechat', 'pinterest', 'instagram', 'subscribe', 'try now', 'get a quote', 'http',  \n",
    "                'javascript', 'my personal information', 'hiring', 'skip to','infographic', 'technical support', 'email us',\n",
    "                ' more', 'follow us', 'terms of service', 'conditions', 'user agreement', 'not yet registered', 'show me',\n",
    "                'forgot password', 'careers', 'jobs', 'live chat', 'tour today', 'sign in', 'sign out', 'help guide', \n",
    "                'question', 'testimonials', 'for a demo', 'schedule a call', 'google', 'instant demo', 'english', \n",
    "                'how it works', 'reference', 'vacanc', 'apply','demo today', 'open position', 'video', 'book demo',\n",
    "                'item', 'software demo', 'engaging', 'tweet', 'online review', 'learn more', 'e-mail', 'contact form', \n",
    "                'buy now', 'open menu', 'full team', 'article', 'social media', 'polic', 'client portal', 'speaker', \n",
    "                'customer support', 'code of conduct', 'a demo', 'out more', 'north america', 'podcast', 'help center', \n",
    "                'create account', 'chat with us', 'request pricing', 'personal demo', 'acknowledge', 'github', 'android',\n",
    "                'ios', 'window', 'messenger', 'continue', 'disclaimer', 'meeting', 'go to', 'your demo', 'talk to', \n",
    "                'send message', 'we are', 'a message', 'help desk', 'sign-in', 'sign-out', 'contact sales', 'to top',\n",
    "                '@', '\\.com', 'www\\.', '__', '{', '}', '\\..', '\\[#', '\\.js']\n",
    "\n",
    "# Note: In reg-ex for using special characters like '.' or '[' or '#' as search string, always use escape character '\\'\n",
    "#       before the actual search string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main processing section of code:\n",
    "- For each of the URL in the input file, below is performed:\n",
    "    - Download the html page source using browser via Selenium \n",
    "    - Parse the page source using BeautifulSoup\n",
    "    - Eliminate non printable characters and multiple spaces\n",
    "    - Loop thru the key words, stop words, stop phrases and write into respective columns \n",
    "    - Look for duplicate entries and clean up\n",
    "    - Write an entry into output list / error output list\n",
    "    - Close the browser\n",
    "- Load the output list and error output list into dataframes and create respective output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-21d540778e92>:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "out_err = []\n",
    "i = 0\n",
    "\n",
    "for input in input_list:\n",
    "    \n",
    "    comp_name = input[0].strip()    # Capture company name\n",
    "    link = input[1].strip()         # Capture company url\n",
    "    \n",
    "    if \"https://https://\" in link:\n",
    "        link = link.replace(\"https://https://\", \"https://\")\n",
    "    \n",
    "    products, solutions, services, platforms, clients, page_text, overviewpage_link, linkedinpage_link, overview_text = init_lists() # Initialize lists\n",
    "        \n",
    "    try: \n",
    "        browser, page_soup = download_browser(link)                             # Download browser and parse page source \n",
    "        \n",
    "        # Sleep for 3 seconds for the page to respond\n",
    "        time.sleep(3)                                                           # Sleep for 3 seconds for page to respond\n",
    "        \n",
    "        # Capture all tags which have href variable present in them\n",
    "        u_lists = page_soup.find_all(href = re.compile('\\S'))\n",
    "        \n",
    "        \n",
    "        #u_lists = page_soup.find_all(class_ = re.compile(r'(drop)|(nav)|(menu)|(item)|(sub)'), href = re.compile('\\S'))\n",
    "        \n",
    "        for u_list in u_lists:\n",
    "            \n",
    "            # Eliminate all non printable characters in text\n",
    "            txt = re.sub('[^{}]'.format(string.printable), '', u_list.text.strip())\n",
    "            \n",
    "            \n",
    "            # Eliminate multiple spaces in text\n",
    "            txt_list = txt.split()                              \n",
    "            txt = (' ').join(txt_list)\n",
    "                     \n",
    "            if len(txt) > 2 and txt.lower() not in stop_words:                  # Eliminate stop words & unwanted text          \n",
    "                skip_text = False\n",
    "                \n",
    "                for stop_string in stop_strings:                                # Eliminate all stop strings\n",
    "                    if re.search(stop_string.lower(), txt.lower()):\n",
    "                        skip_text = True\n",
    "                        break                        \n",
    "                \n",
    "                # Skip if phone numbers are present and include those strings with less than 10 words\n",
    "                if skip_text == False and len(re.sub('[^0-9]', '', txt)) <= 9 and len(txt_list) < 10:\n",
    "                    href = u_list['href'].strip()\n",
    "                    \n",
    "                    # Match on respective key words and write into respective columns \n",
    "                    for product in products_key:\n",
    "                        if re.search(product.lower(), href.lower()):\n",
    "                            products.append(txt)\n",
    "\n",
    "                    for solution in solutions_key:\n",
    "                        if re.search(solution.lower(), href.lower()):\n",
    "                            solutions.append(txt)\n",
    "\n",
    "                    for service in services_key:\n",
    "                        if re.search(service.lower(), href.lower()):\n",
    "                            services.append(txt)\n",
    "\n",
    "                    for platform in platforms_key:\n",
    "                        if re.search(platform.lower(), href.lower()):\n",
    "                            platforms.append(txt)\n",
    "\n",
    "                    for client in clients_key:\n",
    "                        if re.search(client.lower(), href.lower()):\n",
    "                            clients.append(txt)\n",
    "\n",
    "                    page_text.append(txt)                                       # Capture all extracted & filtered text\n",
    "                    \n",
    "                    links = []\n",
    "                    for pagelink in page_soup.findAll('a'):\n",
    "                        links.append(pagelink.get('href'))\n",
    "                    all_links = []\n",
    "                    linkedinpage_link=[]\n",
    "                    links_inter =[]\n",
    "                    for all_link in links:\n",
    "                        c='/'\n",
    "                        lst = []\n",
    "                        if all_link != None :\n",
    "                            if re.search(linkedin_key, all_link):\n",
    "                                if all_link[-1]==\"/\":\n",
    "                                    linkedinpage_link.append(all_link+\"about/\")\n",
    "                                if all_link[-1]!=\"/\":\n",
    "                                    linkedinpage_link.append(all_link+\"/about/\")\n",
    "                                #linkedinpage_link.append(all_link)\n",
    "                            for pos,char in enumerate(all_link):\n",
    "                                if(char == c):\n",
    "                                    lst.append(pos)\n",
    "                            p=3\n",
    "                            try:\n",
    "                                while  len(links_inter) == 0 and p <= 6:\n",
    "                                    nth = lst[p]+1\n",
    "                                    links_inter1 = all_link[0:nth]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    for key in overviewlinks_key:\n",
    "                                        if re.search(key, links_inter1) and re.search(link, links_inter1):\n",
    "                                            links_inter.append(links_inter1)\n",
    "                                    p = p+1\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                    links_inter1 = []\n",
    "                    links_inter1 = [*set(links_inter)]\n",
    "                    #[links_inter1.append(link_inter1) for link_inter1 in links_inter if link_inter1 not in links_inter1]\n",
    "                    \n",
    "                    for lin_inter in links_inter1:\n",
    "                        try:\n",
    "                            browser2, page_soup2 = download_browser(lin_inter)\n",
    "                            u_lists2 = page_soup2.find_all(\"p\")\n",
    "                            \n",
    "                            for txt2 in u_lists2:\n",
    "                                txt2 = re.sub('[^{}]'.format(string.printable), '', txt2.text.strip())\n",
    "                                overview_text.append(txt2)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "        # Remove duplicates for respective column entries\n",
    "        products_clean = []\n",
    "        #[products_clean.append(product) for product in products if product not in products_clean]\n",
    "        products_clean = [*set(products)]\n",
    "\n",
    "        solutions_clean = []\n",
    "        #[solutions_clean.append(solution) for solution in solutions if solution not in solutions_clean]\n",
    "        solutions_clean = [*set(solutions)]\n",
    "\n",
    "        services_clean = []\n",
    "        #[services_clean.append(service) for service in services if service not in services_clean]\n",
    "        services_clean = [*set(services)]\n",
    "\n",
    "        platforms_clean = []\n",
    "        #[platforms_clean.append(platform) for platform in platforms if platform not in platforms_clean]\n",
    "        platforms_clean = [*set(platforms)]\n",
    "\n",
    "        clients_clean = []\n",
    "        #[clients_clean.append(client) for client in clients if client not in clients_clean]\n",
    "        clients_clean = [*set(clients)]\n",
    "\n",
    "        page_text_clean = []\n",
    "        #[page_text_clean.append(text) for text in page_text if text not in page_text_clean]\n",
    "        page_text_clean = [*set(page_text)]\n",
    "        \n",
    "        overviewpage_link_clean = []\n",
    "        #[overviewpage_link_clean.append(link_inter) for link_inter in links_inter if link_inter not in overviewpage_link_clean]\n",
    "        overviewpage_link_clean = [*set(links_inter)]\n",
    "        \n",
    "        linkedinpage_link_clean = []\n",
    "        #[linkedinpage_link_clean.append(linkedIn_inter) for linkedIn_inter in linkedinpage_link if linkedIn_inter not in linkedinpage_link_clean]\n",
    "        linkedinpage_link_clean = [*set(linkedinpage_link)]\n",
    "        browser.quit() \n",
    "        overviewlk = []\n",
    "        industrylk = []\n",
    "        specialitieslk = []\n",
    "        \n",
    "        overviewlk1 = []\n",
    "        industrylk1 = []\n",
    "        specialitieslk1 = []\n",
    "        \n",
    "        try:\n",
    "            for linkedinpage_link_clean1 in linkedinpage_link_clean:\n",
    "                overviewlk, industrylk, specialitieslk = linkedinscrap(linkedinpage_link_clean1)\n",
    "                overviewlk1.append(\" \".join(str(e) for e in overviewlk))\n",
    "                industrylk1.append(\" \".join(str(e) for e in industrylk))\n",
    "                specialitieslk1.append(\" \".join(str(e) for e in specialitieslk))\n",
    "        except:\n",
    "            pass\n",
    "                      \n",
    "        overview_text_clean = []\n",
    "        [overview_text_clean.append(text) for text in overview_text if text not in overview_text_clean]\n",
    "        \n",
    "        \n",
    "        Company_overview_summary = []\n",
    "        try:\n",
    "            if len(overview_text_clean)>0:\n",
    "                \n",
    "                Company_overview_summary = [query({\"inputs\": str(overview_text_clean),})[0]['summary_text']]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "\n",
    "        write_file()                                                            # Write output record\n",
    "    \n",
    "    except Exception as e:                                                      # Write error record for run time errors\n",
    "        print('url# {}: {} Error: {}'.format(i, link, e))\n",
    "        write_error_file()\n",
    "    finally: \n",
    "        browser.quit()                                                          # Quit the browser for every URL  \n",
    "        \n",
    "        i = i + 1                                                               # Counter tracking # of records processed \n",
    "        if i % 25 == 0:                                                         # Print after every 25 records\n",
    "           print('# of URLs processed:', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It looks like nothing was found at this location. Maybe try a search? Maybe try to find something else? No, it's not that easy. It's just that you can't find anything when you try to look for it. You have to go to a different location and do a search.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_overview_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Load the output list into a DataFrame and export to output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Products</th>\n",
       "      <th>Solutions</th>\n",
       "      <th>Services</th>\n",
       "      <th>Platforms</th>\n",
       "      <th>Clients</th>\n",
       "      <th>Page_Text</th>\n",
       "      <th>overviewpage_Link</th>\n",
       "      <th>linkedinpage_Link</th>\n",
       "      <th>overview_Text</th>\n",
       "      <th>Overview_linkedIn</th>\n",
       "      <th>Industry_linlkedIn</th>\n",
       "      <th>Specialities_linkedIn</th>\n",
       "      <th>Company_Overview_Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simplify Healthcare, Inc.</td>\n",
       "      <td>https://simplifyhealthcare.com</td>\n",
       "      <td></td>\n",
       "      <td>Provider1 | Medicaid Benefit Plan Management |...</td>\n",
       "      <td>Service1 | Service1 Digital Payer Platform</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Provider1 | Medicaid Benefit Plan Management |...</td>\n",
       "      <td>https://simplifyhealthcare.com/about-us/</td>\n",
       "      <td>https://www.linkedin.com/company/simplifyhealt...</td>\n",
       "      <td>Home  About Us  Our Story | Founded in 2008, w...</td>\n",
       "      <td>Simplify Healthcare is one of the leading digi...</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Healthcare IT, Payer Solutions, Benefit System...</td>\n",
       "      <td>Healthcare technology solutions providers offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medecision</td>\n",
       "      <td>https://www.medecision.com/</td>\n",
       "      <td>Aveus Consulting Services</td>\n",
       "      <td>Digital Care Management | Care Coordination | ...</td>\n",
       "      <td>Aveus Consulting Services</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Digital Care Management | Care Coordination | ...</td>\n",
       "      <td>https://www.medecision.com/about-us/</td>\n",
       "      <td>https://www.linkedin.com/company/medecision/ab...</td>\n",
       "      <td>Medecision is a digital care management compan...</td>\n",
       "      <td>Medecision® is a digital care management compa...</td>\n",
       "      <td>Software Development</td>\n",
       "      <td>Population Health Management, Integrated Healt...</td>\n",
       "      <td>Medecision is a digital care management compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ingenious Med Inc.</td>\n",
       "      <td>https://ingeniousmed.com/</td>\n",
       "      <td></td>\n",
       "      <td>National health systems | Data intelligence | ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Compliance Hotline website | National health s...</td>\n",
       "      <td>https://ingeniousmed.com/about-us/</td>\n",
       "      <td>https://www.linkedin.com/company/ingenious-med...</td>\n",
       "      <td>It looks like nothing was found at this locati...</td>\n",
       "      <td>Ingenious Med offers usable solutions that sim...</td>\n",
       "      <td>Hospitals and Health Care</td>\n",
       "      <td>technology, healthcare, sales, marketing, exec...</td>\n",
       "      <td>It looks like nothing was found at this locati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name                            Link  \\\n",
       "0  Simplify Healthcare, Inc.  https://simplifyhealthcare.com   \n",
       "1                 Medecision     https://www.medecision.com/   \n",
       "2         Ingenious Med Inc.       https://ingeniousmed.com/   \n",
       "\n",
       "                    Products  \\\n",
       "0                              \n",
       "1  Aveus Consulting Services   \n",
       "2                              \n",
       "\n",
       "                                           Solutions  \\\n",
       "0  Provider1 | Medicaid Benefit Plan Management |...   \n",
       "1  Digital Care Management | Care Coordination | ...   \n",
       "2  National health systems | Data intelligence | ...   \n",
       "\n",
       "                                     Services Platforms Clients  \\\n",
       "0  Service1 | Service1 Digital Payer Platform                     \n",
       "1                   Aveus Consulting Services                     \n",
       "2                                                                 \n",
       "\n",
       "                                           Page_Text  \\\n",
       "0  Provider1 | Medicaid Benefit Plan Management |...   \n",
       "1  Digital Care Management | Care Coordination | ...   \n",
       "2  Compliance Hotline website | National health s...   \n",
       "\n",
       "                          overviewpage_Link  \\\n",
       "0  https://simplifyhealthcare.com/about-us/   \n",
       "1      https://www.medecision.com/about-us/   \n",
       "2        https://ingeniousmed.com/about-us/   \n",
       "\n",
       "                                   linkedinpage_Link  \\\n",
       "0  https://www.linkedin.com/company/simplifyhealt...   \n",
       "1  https://www.linkedin.com/company/medecision/ab...   \n",
       "2  https://www.linkedin.com/company/ingenious-med...   \n",
       "\n",
       "                                       overview_Text  \\\n",
       "0  Home  About Us  Our Story | Founded in 2008, w...   \n",
       "1  Medecision is a digital care management compan...   \n",
       "2  It looks like nothing was found at this locati...   \n",
       "\n",
       "                                   Overview_linkedIn  \\\n",
       "0  Simplify Healthcare is one of the leading digi...   \n",
       "1  Medecision® is a digital care management compa...   \n",
       "2  Ingenious Med offers usable solutions that sim...   \n",
       "\n",
       "              Industry_linlkedIn  \\\n",
       "0  IT Services and IT Consulting   \n",
       "1           Software Development   \n",
       "2      Hospitals and Health Care   \n",
       "\n",
       "                               Specialities_linkedIn  \\\n",
       "0  Healthcare IT, Payer Solutions, Benefit System...   \n",
       "1  Population Health Management, Integrated Healt...   \n",
       "2  technology, healthcare, sales, marketing, exec...   \n",
       "\n",
       "                            Company_Overview_Summary  \n",
       "0  Healthcare technology solutions providers offe...  \n",
       "1  Medecision is a digital care management compan...  \n",
       "2  It looks like nothing was found at this locati...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame(out, columns = header)\n",
    "df_out.to_csv(out_file, index = False, encoding='utf-8')\n",
    "\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Load the output error list into a DataFrame and export to output error CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company Name, Link, Error]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out_err = pd.DataFrame(out_err, columns = header_err)\n",
    "df_out_err.to_csv(out_file_err, index = False, encoding='utf-8')\n",
    "\n",
    "df_out_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
